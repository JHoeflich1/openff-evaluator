{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Tutorial 02 - Estimating Data Sets\n",
    "\n",
    "In this tutorial we will be estimating the data set we created in the first tutorial using molecular simulation. The \n",
    "tutorial will cover:\n",
    "\n",
    "- defining custom calculation schemas for the properties in our data set.\n",
    "- estimating the data set of properties using an [Evaluator server](../gettingstarted/server.rst) instance.\n",
    "- retrieving the results from the server and performing some simple analysis.\n",
    "\n",
    "For the sake of clarity all warnings will be disabled in this tutorial:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import logging\n",
    "logging.getLogger(\"openforcefield\").setLevel(logging.ERROR)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "*Note: If you are running this example in google colab you will need to run a setup script:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# %run colab_setup.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "*Make sure that you are using a GPU accelerated runtime.*\n",
    "\n",
    "## Loading the Data Set to Estimate\n",
    "\n",
    "We will begin by loading in the data set which we created in the previous tutorial:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from evaluator.datasets import PhysicalPropertyDataSet\n",
    "\n",
    "# data_set_path = \"filtered_data_set.json\"\n",
    "\n",
    "# If you have not yet completed that tutorial or do not have the data set file \n",
    "# available, a copy is provided by the framework:\n",
    "\n",
    "from evaluator.utils import get_data_filename\n",
    "data_set_path = get_data_filename(\"tutorials/tutorial01/filtered_data_set.json\")\n",
    "\n",
    "data_set = PhysicalPropertyDataSet.from_json(data_set_path)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This data set will contain our density and $H_{vap}$ measurements for ethanol and isopropanol. \n",
    "\n",
    "## Defining the Calculation Schemas\n",
    "\n",
    "After loading the data set, the next step we will take will be to define a calculation schema for each types of property \n",
    "in our set. A calculation schema is the blueprint for how a type of property should be calculated using a particular \n",
    "[calculation approach](../layers/calculationlayers.rst), such as directly by simulation, by reprocessing cached \n",
    "simulation data or, in future, a range of other options.\n",
    "\n",
    "The framework has built-in schemas which defining how densities and $H_{vap}$ should be estimated from molecular \n",
    "simulation, covering all of the aspects from coordinate generation, force field assignment, energy minimisation,\n",
    "equilibration and finally the production simulation and data analysis. All of this functionality is defined in terms\n",
    "of the built in [workflow engine](../workflows/workflows.rst), where each of the above steps is implemented as a \n",
    "separate [workflow task](../workflows/protocols.rst).\n",
    "\n",
    "For the purpose of this tutorial, we are going to modify the default calculation schemas to reduce the number of \n",
    "molecules to include in our simulations to speed up the calculations. This step can be skipped entirely if the default\n",
    "options (which we would normally recommend) are acceptable.\n",
    "\n",
    "We can extract the default simulation schemas using the ``default_simulation_schema()`` function::"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from evaluator.properties import Density, EnthalpyOfVaporization\n",
    "\n",
    "density_schema = Density.default_simulation_schema(n_molecules=256)\n",
    "h_vap_schema = EnthalpyOfVaporization.default_simulation_schema(n_molecules=256)\n",
    "\n",
    "from evaluator.client import RequestOptions\n",
    "\n",
    "# Create an options object which defines how the data set should be estimated.\n",
    "estimation_options = RequestOptions()\n",
    "# Specify that we only wish to use molecular simulation to estimate the data set.\n",
    "estimation_options.calculation_layers = [\"SimulationLayer\"]\n",
    "\n",
    "# Add our custom schemas, specifying that the should be used by the 'SimulationLayer'\n",
    "estimation_options.add_schema(\"SimulationLayer\", \"Density\", density_schema)\n",
    "estimation_options.add_schema(\"SimulationLayer\", \"EnthalpyOfVaporization\", h_vap_schema)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "here we override the default number of molecules to include in the simulation (reducing this count down from 1000 to \n",
    "256).\n",
    "\n",
    "We could further use this method to set either the absolute or the relative uncertainty that the property should be \n",
    "estimated to within. If either of these are set, the schemas will be set up to automatically extend any simulations \n",
    "until the target uncertainty in the property has been met. For our purposes however we won't set any targets, leaving \n",
    "the simulations to run for a default 1 ns.   \n",
    "\n",
    "## Launching the Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from evaluator.utils import setup_timestamp_logging\n",
    "setup_timestamp_logging()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Loris ipsum."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from evaluator.backends import ComputeResources\n",
    "from evaluator.backends.dask import DaskLocalCluster\n",
    "\n",
    "calculation_backend = DaskLocalCluster(\n",
    "    number_of_workers=1,\n",
    "    resources_per_worker=ComputeResources(\n",
    "        number_of_threads=1, \n",
    "        number_of_gpus=1, \n",
    "        preferred_gpu_toolkit=ComputeResources.GPUToolkit.CUDA\n",
    "    ),\n",
    ")\n",
    "calculation_backend.start()\n",
    "\n",
    "from evaluator.server import EvaluatorServer\n",
    "\n",
    "evaluator_server = EvaluatorServer(calculation_backend=calculation_backend)\n",
    "evaluator_server.start(asynchronous=True)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Loris ipsum.\n",
    "\n",
    "## Estimating the Data Set\n",
    "\n",
    "Loris ipsum."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "from evaluator.forcefield import SmirnoffForceFieldSource\n",
    "\n",
    "force_field_path = \"openff-1.0.0.offxml\"\n",
    "force_field_source = SmirnoffForceFieldSource.from_path(force_field_path)\n",
    "\n",
    "from evaluator.client import EvaluatorClient\n",
    "evaluator_client = EvaluatorClient()\n",
    "\n",
    "from evaluator.forcefield import ParameterGradientKey\n",
    "\n",
    "requested_gradients = [\n",
    "    ParameterGradientKey(tag=\"vdW\", smirks=\"[#6X4:1]\", attribute=\"epsilon\"),\n",
    "    ParameterGradientKey(tag=\"vdW\", smirks=\"[#6X4:1]\", attribute=\"rmin_half\"),\n",
    "]\n",
    "\n",
    "request, exception = evaluator_client.request_estimate(\n",
    "    property_set=data_set,\n",
    "    force_field_source=force_field_source,\n",
    "    options=estimation_options,\n",
    "    parameter_gradient_keys=requested_gradients,\n",
    ")\n",
    "\n",
    "assert exception is None\n",
    "\n",
    "# Wait for the results.\n",
    "results, exception = request.results(synchronous=True, polling_interval=30)\n",
    "assert exception is None\n",
    "\n",
    "results.json(f\"results.json\", True);"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Loris ipsum.\n",
    "\n",
    "## Analysing the Results\n",
    "\n",
    "Loris ipsum."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "print(len(results.queued_properties))\n",
    "\n",
    "print(len(results.estimated_properties))\n",
    "\n",
    "print(len(results.unsuccessful_properties))\n",
    "print(len(results.exceptions))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Loris ipsum.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Loris ipsum."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}